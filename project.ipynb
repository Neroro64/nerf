{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DD2424 - Project\n",
    "This is an altered version of the method presented in NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis\n",
    "\n",
    "[Project website](http://www.matthewtancik.com/nerf)\n",
    "\n",
    "Components not included in the notebook\n",
    "\n",
    "* 5D input including view directions\n",
    "* Hierarchical Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-164a2c3cce66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    %tensorflow_version 1.x\n",
    "\n",
    "import os, sys\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('tiny_nerf_data.npz'):\n",
    "    !wget https://people.eecs.berkeley.edu/~bmild/nerf/tiny_nerf_data.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load input images and poses. \n",
    "The input images have size (100,100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('tiny_nerf_data.npz')\n",
    "images = data['images']\n",
    "poses = data['poses']\n",
    "focal = data['focal']\n",
    "H, W = images.shape[1:3]\n",
    "print(images.shape, poses.shape, focal)\n",
    "\n",
    "testimg, testpose = images[101], poses[101]\n",
    "images = images[:100,...,:3]\n",
    "poses = poses[:100]\n",
    "\n",
    "plt.imshow(testimg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeRF network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posenc(x):\n",
    "  rets = [x]\n",
    "  for i in range(L_embed):\n",
    "    for fn in [tf.sin, tf.cos]:\n",
    "      rets.append(fn(2.**i * x))\n",
    "  return tf.concat(rets, -1)\n",
    "\n",
    "def get_rays(H, W, focal, c2w):\n",
    "    i, j = tf.meshgrid(tf.range(W, dtype=tf.float32), tf.range(H, dtype=tf.float32), indexing='xy')\n",
    "    dirs = tf.stack([(i-W*.5)/focal, -(j-H*.5)/focal, -tf.ones_like(i)], -1)\n",
    "    rays_d = tf.reduce_sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1)\n",
    "    rays_o = tf.broadcast_to(c2w[:3,-1], tf.shape(rays_d))\n",
    "    return rays_o, rays_d\n",
    "\n",
    "L_embed = 6\n",
    "embed_fn = posenc\n",
    "\n",
    "def init_model(D=8, W=256):\n",
    "    relu = tf.keras.layers.ReLU()    \n",
    "    dense = lambda W=W, act=relu : tf.keras.layers.Dense(W, activation=act)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(3 + 3*2*L_embed)) \n",
    "    outputs = inputs\n",
    "    for i in range(D):\n",
    "        outputs = dense()(outputs)\n",
    "        if i%4==0 and i>0:\n",
    "            outputs = tf.concat([outputs, inputs], -1)\n",
    "    outputs = dense(4, act=None)(outputs)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function\n",
    "render_rays() takes the model and a ray as input. Draw N_samples of points alone the ray. Run the network on these points, use the output to compute the the color and opacity(density). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_rays(network_fn, rays_o, rays_d, near, far, N_samples, rand=False, profiling=False):\n",
    "    forwardTime = renderingTime = 0\n",
    "    def batchify(fn, chunk=1024*32):\n",
    "        return lambda inputs : tf.concat([fn(inputs[i:i+chunk]) for i in range(0, inputs.shape[0], chunk)], 0)\n",
    "    \n",
    "    # Compute 3D query points\n",
    "    z_vals = tf.linspace(near, far, N_samples) \n",
    "    if rand:\n",
    "      z_vals += tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "    pts = rays_o[...,None,:] + rays_d[...,None,:] * z_vals[...,:,None]\n",
    "    \n",
    "    # Run network\n",
    "    pts_flat = tf.reshape(pts, [-1,3])\n",
    "    pts_flat = embed_fn(pts_flat)\n",
    "    if (profiling):\n",
    "        t1 = time.time()\n",
    "        raw = batchify(network_fn)(pts_flat)\n",
    "        forwardTime = time.time() - t1\n",
    "    else:\n",
    "        raw = batchify(network_fn)(pts_flat)\n",
    "    raw = tf.reshape(raw, list(pts.shape[:-1]) + [4])\n",
    "    \n",
    "    # Compute opacities and colors\n",
    "    if (profiling):\n",
    "        t2 = time.time()\n",
    "    sigma_a = tf.nn.relu(raw[...,3])\n",
    "    rgb = tf.math.sigmoid(raw[...,:3]) \n",
    "    \n",
    "    # Do volume rendering\n",
    "    dists = tf.concat([z_vals[..., 1:] - z_vals[..., :-1], tf.broadcast_to([1e10], z_vals[...,:1].shape)], -1) \n",
    "    alpha = 1.-tf.exp(-sigma_a * dists)  \n",
    "    weights = alpha * tf.math.cumprod(1.-alpha + 1e-10, -1, exclusive=True)\n",
    "    \n",
    "    rgb_map = tf.reduce_sum(weights[...,None] * rgb, -2) \n",
    "    depth_map = tf.reduce_sum(weights * z_vals, -1) \n",
    "    acc_map = tf.reduce_sum(weights, -1)\n",
    "    \n",
    "    if (profiling):\n",
    "        renderingTime = time.time() - t2\n",
    "    return rgb_map, depth_map, acc_map, forwardTime, renderingTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render a single image of the scene "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model()\n",
    "optimizer = tf.keras.optimizers.Adam(5e-4)\n",
    "\n",
    "N_samples = 64\n",
    "N_iters = 1000\n",
    "psnrs = []\n",
    "iternums = []\n",
    "i_plot = 25\n",
    "\n",
    "import time\n",
    "t = time.time()\n",
    "for i in range(N_iters+1):\n",
    "    forwardTime = renderingTime = backPropTime = 0\n",
    "\n",
    "    img_i = np.random.randint(images.shape[0])\n",
    "    target = images[img_i]\n",
    "    pose = poses[img_i]\n",
    "    rays_o, rays_d = get_rays(H, W, focal, pose)\n",
    "    with tf.GradientTape() as tape:\n",
    "        rgb, depth, acc, forwardTime, renderingTime = render_rays(model, rays_o, rays_d, near=2., far=6., N_samples=N_samples, rand=True)\n",
    "    \n",
    "    t3 = time.time()\n",
    "    loss = tf.reduce_mean(tf.square(rgb - target))\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    backPropTime = time.time() - t3\n",
    "\n",
    "    if i%i_plot==0:\n",
    "        print(i, (time.time() - t) / i_plot, 'secs per iter')\n",
    "        t = time.time()\n",
    "        print(\"Feedforward phase: {}\".format(forwardTime))\n",
    "        print(\"Rendering phase: {}\".format(renderingTime))\n",
    "        print(\"Optimization phase: {}\".format(backPropTime))\n",
    "        # Render the holdout view for logging\n",
    "        rays_o, rays_d = get_rays(H, W, focal, testpose)\n",
    "        rgb, depth, acc = render_rays(model, rays_o, rays_d, near=2., far=6., N_samples=N_samples)\n",
    "        loss = tf.reduce_mean(tf.square(rgb - testimg))\n",
    "        psnr = -10. * tf.math.log(loss) / tf.math.log(10.)\n",
    "\n",
    "        psnrs.append(psnr.numpy())\n",
    "        iternums.append(i)\n",
    "        print(\"PSNR: {}\".format(psnr))\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(rgb)\n",
    "        plt.title(f'Iteration: {i}')\n",
    "        plt.subplot(122)\n",
    "        plt.plot(iternums, psnrs)\n",
    "        plt.title('PSNR')\n",
    "        plt.show()\n",
    "\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit5c11b25ccdc540ceb1df2efcccf696e8",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}